{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f72a549-794b-4ebf-a08e-7c322be85864",
   "metadata": {},
   "source": [
    "# LangChain Tutorial 1\n",
    "___\n",
    "LangChain tutorial one.\n",
    "\n",
    "Example:\n",
    "```bash \n",
    "$ python langchain_tutorial_1.py\n",
    "```\n",
    "\n",
    "Developers:\n",
    "- Brady Lange (08/17/2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa6fc5-10e4-4d5e-8743-62b14d3dc50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://youtu.be/nE2skSRWTTs\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
    "from langchain.llms import OpenAI, AzureOpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd5933a-a07f-4872-b99b-04d1000abc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACEHUB_API_KEY = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# # When using Microsoft Azure\n",
    "# os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "# # API version to use\n",
    "# os.environ[\"OPENAI_API_VERSION\"] = \"2022-12-01\"\n",
    "# # Base URL for your Azure OpenAI resource\n",
    "# os.environ[\"OPENAI_API_BASE\"] = \"https://your-resource-name.openai.azure.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29572ced-112a-482a-96da-ae0a2bd91dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Huggingface LLM (https://huggingface.co/google/flan-t5-xl)\n",
    "flan_t5_lg = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-large\",\n",
    "    model_kwargs={\"temperature\": 1e-10},\n",
    "    huggingfacehub_api_token=HUGGINGFACEHUB_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ad7dcd-c820-4af7-9952-fcfbe7a46a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt template for simple question/answering\n",
    "sing_template = \"\"\"\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "print(f\"Single Template:\\n{sing_template}\\n\")\n",
    "short_prompt = PromptTemplate(template=sing_template, input_variables=[\"question\"])\n",
    "print(f\"Short Prompt:\\n{short_prompt}\\n\")\n",
    "\n",
    "flan_t5_lg_llm_chain = LLMChain(\n",
    "    prompt=short_prompt,\n",
    "    llm=flan_t5_lg\n",
    ")\n",
    "print(f\"Large Language Model Chain:\\n{flan_t5_lg_llm_chain}\\n\")\n",
    "\n",
    "sing_question = \"What color are zebras?\"\n",
    "print(f\"Single Question:\\n{sing_question}\\n\")\n",
    "\n",
    "flan_t5_lg_sing_answer = flan_t5_lg_llm_chain.run(sing_question)\n",
    "print(f\"Single Answer:\\n{flan_t5_lg_sing_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2726dd-f574-4e28-8f2d-f2e9e6611758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Only works with larger models at this time (08/17/2023)\n",
    "multi_template = \"\"\"\n",
    "Answer each question one at a time separated by a bullet point.\n",
    "\n",
    "Questions:\n",
    "{questions}\n",
    "\n",
    "Answers:\n",
    "\"\"\"\n",
    "print(f\"Multiple Template:\\n{multi_template}\\n\")\n",
    "\n",
    "long_prompt = PromptTemplate(template=multi_template, input_variables=[\"questions\"])\n",
    "print(f\"Long Prompt:\\n{long_prompt}\\n\")\n",
    "\n",
    "multi_str_questions = (\n",
    "    \"What is the location of the team, Minnesota Vikings?\\n\" +\n",
    "    \"How many wins and losses throughout history do the Minnesota Vikings have?\\n\" +\n",
    "    \"What color is an elephant?\\n\" +\n",
    "    \"What color is the Sun?\\n\" +\n",
    "    \"How many planets are in the solar system?\"\n",
    ")\n",
    "print(f\"Multiple String Questions:\\n{multi_str_questions}\\n\")\n",
    "\n",
    "flan_t5_lg_multi_str_answers = flan_t5_lg_llm_chain.run(multi_str_questions)\n",
    "print(f\"Multiple String Answers:\\n{flan_t5_lg_multi_str_answers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7556c5-4004-43e0-b5ad-e5bd8a0e3321",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_questions = [\n",
    "    {\"question\": \"What is the location of the team, Minnesota Vikings?\"},\n",
    "    {\"question\": \"How many wins and losses throughout history do the Minnesota Vikings have?\"},\n",
    "    {\"question\": \"What color is an elephant?\"},\n",
    "    {\"question\": \"What color is the Sun?\"},\n",
    "    {\"question\": \"How many planets are in the solar system?\"}\n",
    "]\n",
    "\n",
    "flan_t5_lg_multi_answers = flan_t5_lg_llm_chain.generate(multi_questions)\n",
    "\n",
    "print(flan_t5_lg_multi_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b17c7a-31d6-4dae-97b7-9c9c9f3a7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "davinci = OpenAI(model_name=\"text-davinci-003\")\n",
    "print(davinci)\n",
    "\n",
    "# # When using Microsoft Azure\n",
    "# davinci_azure = AzureOpenAI(\n",
    "#     deployment_name=\"your-azure-deployment\",\n",
    "#     model_name=\"text-davinci-003\"\n",
    "# )\n",
    "# print(davinci_azure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac0a73-b961-47b5-8977-0aa8a09bb350",
   "metadata": {},
   "outputs": [],
   "source": [
    "davinci_llm_chain = LLMChain(\n",
    "    prompt=short_prompt,\n",
    "    llm=davinci\n",
    ")\n",
    "\n",
    "davinci_sing_answer = davinci_llm_chain.run(sing_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd940f6d-dd17-4a88-aaf7-43a7019ef3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(davinci_sing_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05d156-5a7f-490c-8185-0e13f5b7ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "davinci_multi_answers = davinci_llm_chain.generate(multi_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb397d-6847-4b7f-acbc-b586892537e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(davinci_multi_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacacbb7-732a-4f47-a519-a3eef148299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "davinci_llm_chain = LLMChain(\n",
    "    prompt=long_prompt,\n",
    "    llm=davinci\n",
    ")\n",
    "\n",
    "davinci_multi_str_answers = davinci_llm_chain.run(multi_str_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508b3d5-566e-4e3e-9bfa-0ac8825694f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(davinci_multi_str_answers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
